# -*- coding: utf-8 -*-
"""
Created on Tue Feb 23 11:32:59 2021

@author: subha
"""

# -*- coding: utf-8 -*-
"""
Created on Mon Feb  8 11:11:38 2021

@author: subha
"""

from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
import numpy as np
import cv2
import cvlib as cv
import imutils

                    
# load model- loads a model already saved
model = load_model('C:/Users/subha/Downloads/gender_detection.model')

# open video
webcam = cv2.VideoCapture('C:/Users/subha/Desktop/project-final/vedio9.mp4')
    
classes = ['man','woman']

def Check(a,  b):
    dist = ((a[0] - b[0]) ** 2  +  (a[1] - b[1]) ** 2 ) ** 0.5
     
    
    if 0 < dist < 300:
        return True
    else:
        return False



# loop through frames
while webcam.isOpened():

    # read frame from video 
    status, frame = webcam.read()
    if status:
        
        center = []
        status = []
        pairs = []
        violate=0
        
        #resize the image without changing aspect ratio- hence uses only width or height
        frame=imutils.resize(frame,width=min(800,frame.shape[1]))

        # apply face detection- returns bounding box corners - 
        #Underneath it is using OpenCVâ€™s dnn module with a pre-trained caffemodel to detect faces
        #confidence gives the distance to nearest database item
        face, confidence = cv.detect_face(frame)
    

        person=1

        # loop through detected faces
        #enumerate returns counter in form of enumerate object
        for idx, f in enumerate(face):

            # get corner points of face rectangle        
            (startX, startY) = f[0], f[1]
            (endX, endY) = f[2], f[3]
            center.append([int(startX + endX / 2), int(startY + endY / 2)])
            status.append(False)
        

            # draw rectangle over face
            cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)
            person=person+1
            # crop the detected face region
            #returns array
            face_crop = np.copy(frame[startY:endY,startX:endX])
            #shape- returns a tuple which gives the number of rows and columns-(row,column)
            
            
            #size too small - maybe wrong detection
            if (face_crop.shape[0]) < 10 or (face_crop.shape[1]) < 10:
                continue

            # preprocessing for gender detection model
            face_crop = cv2.resize(face_crop, (96,96))
            #cast to float
            face_crop = face_crop.astype("float") / 255.0
            #converts the image to numpy array
            face_crop = img_to_array(face_crop)
            #expands the dimensions of the array
            #numpy.expand_dims(arr, axis)- axis is the position where the new axis is to be placed
            face_crop = np.expand_dims(face_crop, axis=0)

            # apply gender detection on face
            conf = model.predict(face_crop)[0] # model.predict return a 2D matrix, ex: [[9.9993384e-01 7.4850512e-05]]

            # get label with max accuracy
            idx = np.argmax(conf)
            label = classes[idx]

            label = "{}: {:.2f}%".format(label, conf[idx] * 100)

            Y = startY - 10 if startY - 10 > 10 else startY + 10

            # write label and confidence above face rectangle
            cv2.putText(frame, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,0.7, (0, 255, 0), 2)
        for i in range(len(center)):
            
            for j in range(len(center)):
                close = Check(center[i], center[j])
            

                if close:
                    pairs.append([center[i], center[j]])
                    status[i] = True
                    status[j] = True
                    violate = violate + 1
                    
        cv2.putText(frame, f'No of people : {person-1}', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)
        cv2.putText(frame, f'No of violations : {violate-1}', (40,60), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)
    # display output
    cv2.imshow("gender detection", frame)

    # press "Q" to stop
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# release resources
webcam.release()
cv2.destroyAllWindows()
